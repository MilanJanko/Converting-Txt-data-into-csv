{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Project script is made for reading several .txt files, containing some data in several columns, converting them into valid dataframe and sorting values according to the relevant column.\n",
    "Files need to be processed and combined into one .csv file, data needs to be wrangled and excluded of Nan values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-27T14:05:34.141218600Z",
     "start_time": "2023-07-27T14:05:32.870861600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initializing empty Dataframe and function which will add empty row at the end of each .txt file, since last row is always shown as bad one and Pandas skips it."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "combined_files = pd.DataFrame()\n",
    "def add_rows_to_text_file(file_path):\n",
    "    with open(file_path, 'a') as file:\n",
    "        file.write('\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T16:56:58.656204100Z",
     "start_time": "2023-07-24T16:56:58.640577Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "directory = \"C:/Users\\Anja/Downloads/relative importance inputs\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T16:56:58.671821200Z",
     "start_time": "2023-07-24T16:56:58.656204100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Function which needs to split each row by two conditions: 1. Whitespaces between each data columns need to be >2; 2. Int or float values are read as one without splitting. However, there are several rows that had only 1 whitespace between them, which caused me to build another split_col function to further split rows."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def split_string(x):\n",
    "    if isinstance(x, str):\n",
    "        if re.search(r'\\s{2,}', x):\n",
    "            return re.split(r'\\s{2,}', x)\n",
    "    return x\n",
    "\n",
    "def split_col(x):\n",
    "    return x.split(maxsplit=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T16:56:58.984555800Z",
     "start_time": "2023-07-24T16:56:58.941868Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Processing/ reading files into Dataframe, skipping header rows (7) and creating rows with tab as delimiter. All of files are then concating into one Dataframe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def process_and_combine_files(directory):\n",
    "    combined_data = pd.DataFrame()  # Initialize an empty DataFrame to store the combined data\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".txt\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            #add_rows_to_text_file(file_path)\n",
    "            year = filename.split('.')[0][-4:]\n",
    "            data = pd.read_csv(file_path, delimiter='\\t', on_bad_lines='skip', skiprows=7)\n",
    "            data.columns = ['Podaci']\n",
    "            data['Podaci'] = data['Podaci'].apply(split_string)\n",
    "            data = data['Podaci'].apply(pd.Series)\n",
    "            del data[data.columns[-1]]\n",
    "            data.columns = ['Item Code', 'Item and Group', 'CPI-U', 'CPI-W']\n",
    "            data['Year'] = year\n",
    "            combined_data = pd.concat([combined_data, data], ignore_index=True)\n",
    "\n",
    "    return combined_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I've used this piece of code to try my function on single .txt file, so I can test and correct errors in code and final data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "file_path = os.path.join(directory, \"1988.txt\")\n",
    "out_dir_proba = \"E:/\"\n",
    "data1 = pd.read_csv(file_path, delimiter=\"\\t\", on_bad_lines='skip', skiprows=7)\n",
    "data1.columns = ['Podaci']\n",
    "data1['Podaci'] = data1['Podaci'].apply(split_string)\n",
    "data1 = data1['Podaci'].apply(pd.Series)\n",
    "out_proba = os.path.join(out_dir_proba, 'one_file.csv')\n",
    "data1.to_csv(out_proba, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T17:10:07.062449100Z",
     "start_time": "2023-07-24T17:10:07.015573200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Combining files created several rows that had Nan values ( usually data that was represented  in 2 rows). Correcting rows is merging 2 rows into one, combining first column (string) into one string and merging float values into one value. Then, I erased rows which had all Nan values in second and third column."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "  Item Code                        Item and Group   CPI-U   CPI-W  Year\n0       SAC                           COMMODITIES  45.531  49.440  1987\n1      SACE                    ENERGY COMMODITIES   3.716   4.418  1987\n2     SACL1                 COMMODITIES LESS FOOD  29.476  31.648  1987\n3    SACL1E      COMMODITIES LESS FOOD AND ENERGY  25.760  27.230  1987\n4   SACL1E4  COMMODITIES LESS FOOD, ENERGY, & UCR  24.447  24.884  1987",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Item Code</th>\n      <th>Item and Group</th>\n      <th>CPI-U</th>\n      <th>CPI-W</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SAC</td>\n      <td>COMMODITIES</td>\n      <td>45.531</td>\n      <td>49.440</td>\n      <td>1987</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>SACE</td>\n      <td>ENERGY COMMODITIES</td>\n      <td>3.716</td>\n      <td>4.418</td>\n      <td>1987</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>SACL1</td>\n      <td>COMMODITIES LESS FOOD</td>\n      <td>29.476</td>\n      <td>31.648</td>\n      <td>1987</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>SACL1E</td>\n      <td>COMMODITIES LESS FOOD AND ENERGY</td>\n      <td>25.760</td>\n      <td>27.230</td>\n      <td>1987</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>SACL1E4</td>\n      <td>COMMODITIES LESS FOOD, ENERGY, &amp; UCR</td>\n      <td>24.447</td>\n      <td>24.884</td>\n      <td>1987</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = process_and_combine_files(directory)\n",
    "bad_rows = df[df['CPI-W']== '']\n",
    "def correct_rows(rows):\n",
    "    for i in range(len(rows.index)):\n",
    "        change = split_col(str(rows.iloc[i][0]))\n",
    "        rows.iloc[i]= [change[0], change[1], rows.iloc[i][1], rows.iloc[i][2], rows.iloc[i][4]]\n",
    "    return rows\n",
    "corrected = correct_rows(bad_rows)\n",
    "df.update(corrected)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T17:19:24.195303800Z",
     "start_time": "2023-07-24T17:19:23.693881700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Deduping files by each column to see if there are any duplicates."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicate rows within each year.\n"
     ]
    }
   ],
   "source": [
    "def dedupe(files):\n",
    "    duplicates_by_year = files.duplicated(subset=['Year', 'Item Code', 'Item and Group', 'CPI-U', 'CPI-W'], keep=False)\n",
    "    return duplicates_by_year\n",
    "\n",
    "deduped = dedupe(df)\n",
    "\n",
    "# Check if there are any True values in deduped Series\n",
    "if deduped.any():\n",
    "    count_of_duplicates = deduped.sum()\n",
    "    print(\"There are {} duplicate rows within each year.\".format(count_of_duplicates))\n",
    "else:\n",
    "    print(\"There are no duplicate rows within each year.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T17:40:37.030750100Z",
     "start_time": "2023-07-24T17:40:36.968656200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Quick piece of code if there were to happen that we had duplicates and wanted to save original and deduped data into 2 separate sheets.\n",
    "\n",
    "out_dir = \"E:/\"\n",
    "\n",
    "output_csv_file = os.path.join(out_dir, \"combined_files.xlsx\")\n",
    "\n",
    "with pd.ExcelWriter(output_csv_file) as writer:\n",
    "    # Save the original DataFrame to the first sheet (Sheet Name: 'Original Data')\n",
    "    df.to_excel(writer, sheet_name='Combined Files', index=False)\n",
    "    deduped.to_excel(writer, sheet_name='Duplicated', index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "     Item Code Item and Group  CPI-U  CPI-W  Year\n3359    SE3805  WOMEN'S SUITS  0.165  0.108  1995\n2969    SE3805  WOMEN'S SUITS  0.179  0.117  1994\n1799    SE3805  WOMEN'S SUITS  0.184  0.121  1991\n629     SE3805  WOMEN'S SUITS  0.175  0.118  1988\n1409    SE3805  WOMEN'S SUITS  0.172  0.115  1990\n...        ...            ...    ...    ...   ...\n2699    SE6203     ADMISSIONS  0.683  0.586  1993\n1919    SE6203     ADMISSIONS  0.683  0.584  1991\n2309    SE6203     ADMISSIONS  0.689  0.589  1992\n3879    SE6203     ADMISSIONS  0.714  0.613  1996\n1529    SE6203     ADMISSIONS  0.671  0.573  1990\n\n[3910 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Item Code</th>\n      <th>Item and Group</th>\n      <th>CPI-U</th>\n      <th>CPI-W</th>\n      <th>Year</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3359</th>\n      <td>SE3805</td>\n      <td>WOMEN'S SUITS</td>\n      <td>0.165</td>\n      <td>0.108</td>\n      <td>1995</td>\n    </tr>\n    <tr>\n      <th>2969</th>\n      <td>SE3805</td>\n      <td>WOMEN'S SUITS</td>\n      <td>0.179</td>\n      <td>0.117</td>\n      <td>1994</td>\n    </tr>\n    <tr>\n      <th>1799</th>\n      <td>SE3805</td>\n      <td>WOMEN'S SUITS</td>\n      <td>0.184</td>\n      <td>0.121</td>\n      <td>1991</td>\n    </tr>\n    <tr>\n      <th>629</th>\n      <td>SE3805</td>\n      <td>WOMEN'S SUITS</td>\n      <td>0.175</td>\n      <td>0.118</td>\n      <td>1988</td>\n    </tr>\n    <tr>\n      <th>1409</th>\n      <td>SE3805</td>\n      <td>WOMEN'S SUITS</td>\n      <td>0.172</td>\n      <td>0.115</td>\n      <td>1990</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2699</th>\n      <td>SE6203</td>\n      <td>ADMISSIONS</td>\n      <td>0.683</td>\n      <td>0.586</td>\n      <td>1993</td>\n    </tr>\n    <tr>\n      <th>1919</th>\n      <td>SE6203</td>\n      <td>ADMISSIONS</td>\n      <td>0.683</td>\n      <td>0.584</td>\n      <td>1991</td>\n    </tr>\n    <tr>\n      <th>2309</th>\n      <td>SE6203</td>\n      <td>ADMISSIONS</td>\n      <td>0.689</td>\n      <td>0.589</td>\n      <td>1992</td>\n    </tr>\n    <tr>\n      <th>3879</th>\n      <td>SE6203</td>\n      <td>ADMISSIONS</td>\n      <td>0.714</td>\n      <td>0.613</td>\n      <td>1996</td>\n    </tr>\n    <tr>\n      <th>1529</th>\n      <td>SE6203</td>\n      <td>ADMISSIONS</td>\n      <td>0.671</td>\n      <td>0.573</td>\n      <td>1990</td>\n    </tr>\n  </tbody>\n</table>\n<p>3910 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by='Item and Group', ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T18:38:19.862019700Z",
     "start_time": "2023-07-24T18:38:19.831504600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "out_dir = \"E:/\"\n",
    "\n",
    "output_csv_file = os.path.join(out_dir, \"combined_files.csv\")\n",
    "\n",
    "df.to_csv(output_csv_file, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-24T17:41:54.050424100Z",
     "start_time": "2023-07-24T17:41:54.017084400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
